{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Function Utils\n",
    "def rand_centroids(K, X):\n",
    "    # rand_centroids(K=Int, X=Float_array):\n",
    "    # Return a numpy array of size K with each element \n",
    "    # being a normally random distributed var with mu and sigma calculated \n",
    "    # from the mean and std of the data X\n",
    "    mean, std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "    clusters = [np.random.normal(mean, std) for n in range(K)]\n",
    "    return np.array(clusters)\n",
    "\n",
    "def euc_distance(X, Y):    \n",
    "    # euc_distance(X=Float_array, Y=Float_array):\n",
    "    # Returns an array of euclidean distances, \n",
    "    # for the square root of the sum of the square of the differences\n",
    "    # of array X and array Y\n",
    "    diff = X - Y[:, np.newaxis]\n",
    "    squared_diff = diff**2\n",
    "    sum_squared_diff = squared_diff.sum(axis=2)\n",
    "    return np.sqrt(sum_squared_diff)\n",
    "\n",
    "def compute_clusters(K, C, X):\n",
    "    # compute_clusters(K=Int, C=Float_array, X=Float_array)\n",
    "    # Compute the clusters for cluster size K, clusters C and data X\n",
    "    # where a new cluster is calculated as the mean of the data points \n",
    "    # which share a common nearest cluster. Repeats until the sum of\n",
    "    # the euc distances between clusters and points does not change, \n",
    "    # then returns the clusters\n",
    "    D = euc_distance(X, C)\n",
    "    CC = np.argmin(D, axis=0)\n",
    "    C = np.array([new_cluster(k, X, CC) for k in range(K)])\n",
    "    D2 = euc_distance(X, C)\n",
    "    if (D.sum() == D2.sum()):\n",
    "        return C, np.argmin(D2, axis=0)\n",
    "    else:\n",
    "        return compute_clusters(K, C, X)\n",
    "\n",
    "def new_cluster(k, X, CC):\n",
    "    # Returns a new cluster based on the mean of the points associated with it\n",
    "    # if no points associated with it, generates a new one\n",
    "    x = X[CC==k]\n",
    "    if (len(x) > 0):\n",
    "        return x.mean(axis=0)\n",
    "    else: \n",
    "        return rand_centroids(1, X)[0]\n",
    "    \n",
    "def k_means(K, X):\n",
    "    # k_means(K=Int, X=Float_array)\n",
    "    # K-means for clust size K on dataset X using random initialised centroids\n",
    "    # returns final clusters and predicted labels\n",
    "    C = rand_centroids(K, X)\n",
    "    return compute_clusters(K, C, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load iris data set values into a numpy array\n",
    "iris_data, iris_meta = loadarff('./datasets/iris.arff')\n",
    "data = np.array([[v[0], v[1], v[2], v[3]] for v in iris_data])\n",
    "labels = np.unique([v[4] for v in iris_data])\n",
    "labels_true = np.array([np.where(labels == v[4])[0][0] for v in iris_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.30103093  2.88659794  4.95876289  1.69587629]\n",
      " [ 5.00566038  3.36037736  1.56226415  0.28867925]]\n"
     ]
    }
   ],
   "source": [
    "# Perform k-means test\n",
    "K = 2\n",
    "clusters, labels_pred = k_means(K, data)\n",
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.00566038  3.36037736  1.56226415  0.28867925]\n",
      " [ 6.30103093  2.88659794  4.95876289  1.69587629]]\n"
     ]
    }
   ],
   "source": [
    "# SK-learn k-means comparison test\n",
    "from sklearn.cluster import KMeans\n",
    "sk_means = KMeans(n_clusters=K, init='random').fit(data)\n",
    "print(sk_means.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53992182942071232"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "adjusted_rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "513.30384335175665"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calinski harabaz score\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "calinski_harabaz_score(data, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform scores for each metric and several clusters\n",
    "MAX_K = 20\n",
    "accuracies = []\n",
    "for k in range(2, MAX_K):\n",
    "    clusters, labels_pred = k_means(k, data)\n",
    "    rand_score = adjusted_rand_score(labels_true, labels_pred)\n",
    "    calinski = calinski_harabaz_score(labels_pred,)\n",
    "    accuracies.append([rand_score, calinski])\n",
    "accuracies = np.array(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file:///Users/jnalexander/Projects/MAI-machine-learning/temp-plot.html'"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the accuracies on a graph \n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly.graph_objs import Scatter, Figure, Layout\n",
    "\n",
    "traces = [\n",
    "    Scatter(x=range(2, MAX_K), y=accuracies[:,0], name = 'adjusted_rand_score'),\n",
    "    Scatter(x=range(2, MAX_K), y=accuracies[:,1], name = 'calinski_score', yaxis='y2')\n",
    "]\n",
    "\n",
    "yaxis2=dict(side='right')\n",
    "layout = Layout(\n",
    "    title='K-means Metrics over cluster size 2-20',\n",
    "    xaxis=dict(title='cluster_size'),\n",
    "    yaxis=dict(title='adjusted_rand_score'),\n",
    "    yaxis2=dict(title='calinski_score', overlaying='y', side='right')\n",
    ")\n",
    "\n",
    "fig = Figure(data=traces, layout=layout)\n",
    "plot(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
