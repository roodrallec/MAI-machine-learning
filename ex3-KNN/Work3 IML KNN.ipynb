{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this work, you will implement K-Nearest Neighbor algorithm with weighting and with feature selection. You may select two data sets (large enough to extract conclusions) for your analysis. At the end, you will find a list of the data sets available.\n",
    "You will use your code in Python to extract the performance of the different combinations. Performance will be measured in terms of classification accuracy and efficiency. The accuracy measure is the average of correctly classified cases. That is the number of correctly classified\n",
    "instances divided by the total of instances in the test file. The efficiency is the average problem- solving time. For the evaluation, you will use a T-Test or another statistical method [2].\n",
    "From the accuracy and efficiency results, you will extract conclusions showing graphs of such evaluation and reasoning about the results obtained.\n",
    "In your analysis, you will include several considerations.\n",
    "1. You will analyze the KNN (with no weighting or selection). You will analyze which is the\n",
    "most suitable combination of the different parameters analyzed. The one with the highest accuracy. This KNN combination will be named as the best KNN.\n",
    "2. Once you have decided the best KNN combination. You will analyze it in front of using this combination with two feature selection algorithms. The idea is to extract conclusions of which feature selection algorithm is the best one.\n",
    "For example, some of questions that it is expected you may answer with your analysis:\n",
    "- Which is the best value of K at each dataset?\n",
    "- Did you find useful the use of a voting scheme for deciding the solution of the\n",
    "current_instance?\n",
    "- Which is the best similarity function for KNN?\n",
    "- Did you find differences in performance among the KNN and the weighted KNN?\n",
    "- According to the data sets chosen, which feature selection algorithm provides you more\n",
    "advice for knowing the underlying information in the data set?\n",
    "- In the case of the feature selection KNN, how many features where removed? Which are\n",
    "the features selected for each one the feature selection algorithms?\n",
    "- Which criterion have you used to decide the features that should be removed?\n",
    "Apart from explaining your decisions and the results obtained, it is expected that you reason each one of these questions along your evaluation.\n",
    "Additionally, you should explain how to execute your code. Remember to add any reference that you have used in your decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### s-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1\n",
    "\n",
    "Improve the parser developed in previous works in order to use the class attribute, too. \n",
    "Now, you need to read and save the information from a training and their corresponding testing file in a TrainMatrix and a TestMatrix, respectively. \n",
    "Recall that you need to normalize all the numerical attributes in the range [0..1]. \n",
    "Next you have an example of how to normalize one attribute of your data and how to get your original data back:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Normalization\n",
    "\n",
    "bla = 100.*randn(1,10)\n",
    "minVal = min(bla); maxVal = max(bla);\n",
    "norm_data = (bla - minVal) / ( maxVal - minVal ) your_original_data = minVal + norm_data.*(maxVal - minVal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  \n",
    "Write a Python function that automatically repeats the process described in previous step for the 10-fold cross-validation files. That is, read automatically each training case and run each one of the test cases in the selected classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Write a Python function for classifying, using a KNN algorithm, each instance from the TestMatrix using the TrainMatrix to a classifier called kNNAlgorithm(...). You decide the parameters for this classifier. Justify your implementation and add all the references you have considered for your decisions.  K IS A HYPER PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4\n",
    "For the similarity function, you should consider the Hamming, Euclidean, Cosine, and another EXTRA (you decide which one) distance functions. Adapt these distances to handle all kind of attributes (i.e., numerical and categorical). Assume that the KNN algorithm returns the K most similar instances (i.e., also known as cases) from the TrainMatrix to the current_instance. The value of K will be setup in your evaluation to 1, 3, 5, and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        a. To decide the solution of the current_instance, you may consider using two policies: the most similar retrieved case and a voting policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        b. For evaluating the performance of the KNN algorithm, we will use the percentage of correctly classified instances. To this end, at least, you should store the number of cases correctly classified, the number of cases incorrectly classified. This information will be used for the evaluation of the algorithm. You can store your results in a memory data structure or in a file. Keep in mind that you need to compute the average accuracy over the 10-fold cross-validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You can compare your results in terms of classification accuracy and efficiency. Extract conclusions by analyzing two large enough data sets. At least one of these data sets will contain numerical and nominal data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5\n",
    "Modify the kNN algorithm so that it includes a weighted similarity, you will call this algorithm as weightedKNNalgorithm(...). The weights will be extracted using weighting or feature selection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "       a. Modify the similarity functions in the kNN so that it implements a weighted function. Each weight denotes if an attribute is considered or not for the similarity. A weight value of 1.0 denotes that the attribute will be used by the similarity. By contrast, a weight value of 0.0 shows that the attribute is useless and it is not going to be used.\n",
    "    The weights can be extracted using a weighting metrics. You may choose two algorithms (filter or wrapper, as you wish). Use them as a preprocessing step. This means that you will only compute weights in the initial training case-base. For example, you can use ReliefF, Information Gain, or the Correlation, among others. There are several Python Libraries that also include most of the well-known metrics for feature weighting. You can use the implementations that exist in Python for your feature weighting implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Analyze the results of the weightedKNNalgorithm in front of the previous kNNAlgorithm implementation. To do it, setup both algorithms with the best combination obtained in your previous analysis. In this case, you will analyze your results in terms of classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6\n",
    "Modify the weightedKNN algorithm so that it only uses a subset of the most relevant features, you will call this algorithm as selectionKNNalgorithm(...). The selection will be extracted using weighting with an appropriate policy to discard features or feature selection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Modify the similarity functions in the kNN so that it includes a feature selection function. The feature selected will have a weight value of 1.0 and the features not selected will have a weight value of 0 in the similarity function.\n",
    "    You may choose two algorithms (filter or wrapper, as you wish). Use them as a preprocessing step. You may choose a feature selection algorithm or a feature weighting with an appropriate policy to decide which features should be maintained and which ones should be discarded in the similarity computation. You can use the implementations that exist in Python for your feature weighting implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    b. Analyze the results of the selectionKNNalgorithm in front of the previous weightedKNNalgorithm implementation. To do it, setup both algorithms with the best combination obtained in your previous analysis. In this case, you will analyze your results in terms of classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
