{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "from scipy.io import arff\n",
    "from cStringIO import StringIO\n",
    "import pandas\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "import sklearn.metrics.cluster as sk_cluster_m\n",
    "import sklearn.metrics as skmetrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=\"datasets/iris.arff\"\n",
    "data, meta = arff.loadarff(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print meta\n",
    "#print data.size\n",
    "#print len(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Kmeans\n",
    "## Function Utils\n",
    "def rand_centroids(K, X):\n",
    "    # rand_centroids(K=Int, X=Float_array):\n",
    "    # Return a numpy array of size K with each element \n",
    "    # being a normally random distributed var with mu and sigma calculated \n",
    "    # from the mean and std of the data X\n",
    "    mean, std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "    clusters = [np.random.normal(mean, std) for n in range(K)]\n",
    "    return np.array(clusters)\n",
    "\n",
    "def euc_distance(X, Y):    \n",
    "    # euc_distance(X=Float_array, Y=Float_array):\n",
    "    # Returns an array of euclidean distances, \n",
    "    # for the square root of the sum of the square of the differences\n",
    "    # of array X and array Y\n",
    "    diff = X - Y[:, np.newaxis]\n",
    "    squared_diff = diff**2\n",
    "    sum_squared_diff = squared_diff.sum(axis=2)\n",
    "    return np.sqrt(sum_squared_diff)\n",
    "\n",
    "def compute_clusters(K, C, X):\n",
    "    # compute_clusters(K=Int, C=Float_array, X=Float_array)\n",
    "    # Compute the clusters for cluster size K, clusters C and data X\n",
    "    # where a new cluster is calculated as the mean of the data points \n",
    "    # which share a common nearest cluster. Repeats\n",
    "    # until the sum of the euc distances between clusters\n",
    "    # and points does not change\n",
    "    D = euc_distance(X, C)\n",
    "    CC = np.argmin(D, axis=0)\n",
    "    C = []\n",
    "    for k in range(K):\n",
    "        x = X[CC==k]\n",
    "        # if cluster has no points generate a new one\n",
    "        if (len(x) > 0):\n",
    "            C.append(x.mean(axis=0))\n",
    "        else: \n",
    "            C.append(rand_centroids(1, X)[0])\n",
    "        \n",
    "    C = np.array(C)    \n",
    "    D2 = euc_distance(X, C)\n",
    "    if (D.sum() == D2.sum()):\n",
    "        return C\n",
    "    else:\n",
    "        return compute_clusters(K, C, X)\n",
    "\n",
    "def k_means(K, X):\n",
    "    # k_means(K=Int, X=Float_array)\n",
    "    # K-means for clust size K on dataset X using random initialised centroids\n",
    "    C = rand_centroids(K, X)\n",
    "    return compute_clusters(K, C, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisecting K-means: Cost function k-means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squares_dist(x):\n",
    "    #squares_dist(x=ndarray):\n",
    "    #x: matrix N,M. N rows of data variables. \n",
    "    #.  M/2 columns are data features values, M/2 columns are cluster centroid coord. \n",
    "    #returns square distances\n",
    "    \n",
    "    return (sp.spatial.distance.pdist([x[:x.shape[0]/2],x[x.shape[0]/2:]], 'euclidean'))**2\n",
    "\n",
    "\n",
    "def cost_function(data_n,clusters_n, log_level=1):\n",
    "    #cost_function(data_n=ndarray,clusters_n:array)\n",
    "    #data_n: clustered data\n",
    "    #clusters_n: clusters association in the data (size: rows of data_n, 1)\n",
    "    #returns the cost function value\n",
    "    \n",
    "    #Find the centroids of each cluster \n",
    "    mus=np.array([data_n[np.where(clusters_n==k)].mean(axis=0) for k in range(len(np.unique(clusters_n)))])\n",
    "    \n",
    "    #vector of mu feature values of the associated cluster for each data variable\n",
    "    mus_complete=np.empty([clusters_n.shape[0],4])\n",
    "    \n",
    "    for k in range(len(np.unique(clusters_n))):\n",
    "        \n",
    "        mus_complete[np.where(clusters_n==k)]=mus[k]\n",
    "    \n",
    "    #calculate cost function\n",
    "    cost_f=sum(np.apply_along_axis(squares_dist, axis=1,arr=np.concatenate((data_n,mus_complete),axis=1))) \n",
    "    cost_f=cost_f/data_n.shape[0]\n",
    "    \n",
    "    if log_level:\n",
    "        print \"Cost function kmeans split:\",cost_f\n",
    "    return cost_f\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisecting K-means: Cluster division selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_split_cluster(clusters, criteria=\"larger\", log_level=1):\n",
    "    #select_split_cluster (clusters, criteria)\n",
    "    #clusters: vector of data cluster association (1 column)\n",
    "    #criteria= \"larger\". (more option tbi)\n",
    "    #returns de number of the selected cluster.\n",
    "    \n",
    "    selected_key_c=0\n",
    "    number_of_x=[]\n",
    "    \n",
    "    if criteria == \"larger\":\n",
    "        for i in np.nditer(np.unique(clusters)):\n",
    "\n",
    "            number_of_x.append([len(clusters[np.where(clusters==i)]),i])\n",
    "        \n",
    "        selected_key_c=number_of_x[number_of_x.index(max(number_of_x))][1]\n",
    "        \n",
    "        if log_level:\n",
    "            print \"Number of x in each cluster:\", number_of_x\n",
    "\n",
    "    return selected_key_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisecting Kmeans algorithm: MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Bk_means(X, K, k_means_iter=3, log_level=1):\n",
    "    #Bk_means(X=ndarray, K=Int, k_means_iter=3)\n",
    "    #X: data to cluster\n",
    "    #K: number of clusters\n",
    "    #k_means_iter: number of iteretations on the kmeans call. # of split cluster pairs.\n",
    "    #log_level: 0 : no messages, 1 print messages \n",
    "    \n",
    "    # Initialize cluster  assigment with all data\n",
    "    clusters=np.zeros((X.shape[0],1))\n",
    "    \n",
    "    \n",
    "    #Set initial number of cluster to 1 and iterate until number of clusters=K\n",
    "    \n",
    "    for k in range(1,K):\n",
    "        if log_level:\n",
    "            print \"*********** NEW ITERATION ************* \", k\n",
    "        similarity=[]\n",
    "        potential_new_clusters={}\n",
    "\n",
    "        if log_level:\n",
    "            print \"*********select cluster to split******\"\n",
    "        \n",
    "        larger_cluster_index = select_split_cluster(clusters,\"larger\",log_level) #options: larger, heterogeny, \n",
    "        if log_level:\n",
    "            print \"Selected cluster: \", larger_cluster_index\n",
    "        \n",
    "\n",
    "        kmeans_data=X[np.where(clusters==larger_cluster_index),:]\n",
    "        kmeans_data=kmeans_data[0]\n",
    "        \n",
    "        if log_level:\n",
    "            print \"*********Generate 2 clusters with Kmeans ******\"\n",
    "            print \"*********Best of \", k_means_iter,\" results ******\"\n",
    "        \n",
    "        for i in range(0,k_means_iter): \n",
    "        #if k_means_iter >1 then we select best k_means split with similarity \n",
    "            #potential_new_clusters[i] = KMeans(2, \"random\",1).fit_predict(kmeans_data)\n",
    "            #potential_new_clusters[i] = KMeans(2).fit_predict(kmeans_data)\n",
    "            #call to our kmeans function\n",
    "            print k_means(2,kmeans_data)\n",
    "            print k_means(2,kmeans_data).shape\n",
    "            potential_new_clusters[i] = k_means(2,kmeans_data)\n",
    "            similarity.append(cost_function(kmeans_data,potential_new_clusters[i],log_level))\n",
    "        \n",
    "        #Select division based on similarity (min value max similarity)\n",
    "        selected_division=potential_new_clusters[similarity.index(min(similarity))]\n",
    "        \n",
    "        if log_level:\n",
    "            print \"Selected case: \", similarity.index(min(similarity))\n",
    "        \n",
    "        new_clusters=selected_division\n",
    "        new_clusters[np.where(selected_division==1)]=k\n",
    "        new_clusters[np.where(selected_division==0)]=larger_cluster_index\n",
    "\n",
    "        \n",
    "        clusters[np.where(clusters[:]==larger_cluster_index)]=new_clusters\n",
    "\n",
    "    if log_level:\n",
    "        print \"****** END OF BKmeans *********\\n\\n\\n\"    \n",
    "    return clusters.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bisecting K-means: Performance evaluation with Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Performance evaluation with Iris dataset *********\n",
      "\n",
      "\n",
      "\n",
      "[[ 5.00566038  3.36037736  1.56226415  0.28867925]\n",
      " [ 6.30103093  2.88659794  4.95876289  1.69587629]]\n",
      "(2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/georgina/anaconda/envs/IML/lib/python2.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: Mean of empty slice.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c0a8ff29e9be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwanted_K\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mcluster_assingment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBk_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwanted_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkm_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;31m#cluster_assingment=KMeans(wanted_K).fit_predict(data_num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Number of clusters: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwanted_K\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" km_iter: \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mkm_iter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5955bd6aca6f>\u001b[0m in \u001b[0;36mBk_means\u001b[0;34m(X, K, k_means_iter, log_level)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mk_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkmeans_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mpotential_new_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_means\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkmeans_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpotential_new_clusters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#Select division based on similarity (min value max similarity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4eb31945a4d1>\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(data_n, clusters_n, log_level)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#calculate cost function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcost_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msquares_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_n\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmus_complete\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mcost_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcost_f\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdata_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "#check results\n",
    "\n",
    "print \"****** Performance evaluation with Iris dataset *********\\n\\n\\n\" \n",
    "\n",
    "#load dataset IRIS\n",
    "f=\"datasets/iris.arff\"\n",
    "data, meta = arff.loadarff(f)\n",
    "\n",
    "#initialize data ndarrays data_num\n",
    "#. data_num to cluster \n",
    "#. data_label: ground truth classification\n",
    "\n",
    "data_num=np.zeros((len(data), len(data[0])-1))\n",
    "data_label=np.zeros((len(data)))\n",
    "\n",
    "i=0\n",
    "for d in data:\n",
    "    data_num[i,:]=[d[0],d[1],d[2],d[3]]\n",
    "    if d[4]==\"Iris-setosa\":\n",
    "        data_label[i]=0\n",
    "    if d[4]==\"Iris-versicolor\":\n",
    "        data_label[i]=1\n",
    "    if d[4]==\"Iris-virginica\":\n",
    "        data_label[i]=1\n",
    "                    \n",
    "    i=i+1   \n",
    "\n",
    "\n",
    "######### SET wanted_K and km_iter TO PLOT Bisecting K.means results for Iris\n",
    "wanted_K=3\n",
    "km_iter=1\n",
    "plt.figure()\n",
    "\n",
    "for wanted_K in range(2,6):\n",
    "\n",
    "    cluster_assingment=Bk_means(data_num,wanted_K,km_iter,0)\n",
    "    #cluster_assingment=KMeans(wanted_K).fit_predict(data_num)\n",
    "    plt.title([\"Number of clusters: \",wanted_K,\" km_iter: \" , km_iter] )\n",
    "    #plt.subplot(2,2,wanted_K-1)\n",
    "    plt.scatter(data_num[:, 0], data_num[:, 2], c=cluster_assingment)\n",
    "    #plt.text(2, 0.65, [\"Adjusted rand Index: \" , adjusted_rand_score(data_label.flatten(), cluster_assingment.flatten())])\n",
    "    #plt.xlabel(meta[0])\n",
    "    #plt.ylabel(meta[1])\n",
    "    plt.show()\n",
    "    print \"Adjusted rand Index: \" , sk_cluster_m.adjusted_rand_score(data_label.flatten(), cluster_assingment)\n",
    "    print \"V measure score: \" , sk_cluster_m.v_measure_score(data_label.flatten(), cluster_assingment)\n",
    "    print \"Calinski Harabaz Score: \", skmetrics.calinski_harabaz_score(data_num, cluster_assingment) \n",
    "    print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "#### Bisecting Kmeans: Compare algorithm performance to ground truth K=3 (IRIS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53 entries were classified in one cluster of which:\n",
      "\n",
      "Intersection of C1 with Iris setosa  48\n",
      "Intersection of C1 with Iris versicolor  3\n",
      "Intersection of C1  with Iris virgini  0\n",
      "************************************* \n",
      "\n",
      "38 entries were classified in one cluster of which:\n",
      "\n",
      "intersection with Iris setosa  0\n",
      "intersection with Iris versicolor  2\n",
      "intersection with Iris virgini  36\n",
      "************************************* \n",
      "59 entries were classified in one cluster of which:\n",
      "\n",
      "intersection with Iris setosa  0\n",
      "intersection with Iris versicolor  45\n",
      "intersection with Iris virgini\n",
      "  13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_Iris_setosa=data_num[np.where(data[\"class\"]==\"Iris-setosa\")]\n",
    "d_Iris_versicolor=data_num[np.where(data[\"class\"]==\"Iris-versicolor\")]\n",
    "d_Iris_virginica=data_num[np.where(data[\"class\"]==\"Iris-virginica\")]\n",
    "\n",
    "cluster_assingment=Bk_means(data_num,3,2,0)\n",
    "\n",
    "results_c1=data_num[np.where(cluster_assingment[:]==0),:][0]\n",
    "results_c2=data_num[np.where(cluster_assingment[:]==1),:][0]\n",
    "results_c3=data_num[np.where(cluster_assingment[:]==2),:][0]\n",
    "\n",
    "\n",
    "print len(results_c1), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_Iris_setosa)).intersection(map(tuple, list(results_c1)))\n",
    "d=len(sett)\n",
    "print\"Intersection of C1 with Iris setosa \",d\n",
    "sett=set(map(tuple, d_Iris_versicolor)).intersection(map(tuple, results_c1))\n",
    "d=len(sett)\n",
    "print \"Intersection of C1 with Iris versicolor \",d\n",
    "sett=set(map(tuple, d_Iris_virginica)).intersection(map(tuple, results_c1))\n",
    "d=len(sett)\n",
    "print \"Intersection of C1  with Iris virgini \",d\n",
    "\n",
    "print \"************************************* \\n\"\n",
    "\n",
    "print len(results_c2), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_Iris_setosa)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris setosa \",d\n",
    "sett=set(map(tuple, d_Iris_versicolor)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris versicolor \",d\n",
    "sett=set(map(tuple, d_Iris_virginica)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris virgini \",d\n",
    "\n",
    "print \"************************************* \"\n",
    "\n",
    "print len(results_c3), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_Iris_setosa)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris setosa \",d\n",
    "sett=set(map(tuple, d_Iris_versicolor)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris versicolor \",d\n",
    "sett=set(map(tuple, d_Iris_virginica)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Iris virgini\\n \",d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Bisecting Kmeans: Compare algorithm performance to ground truth K=3 (BALANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Performance evaluation with Balance dataset *********\n",
      "\n",
      "\n",
      "\n",
      "625\n",
      "There are 288 entries classified as L in Bal data file\n",
      "There are 49 entries classified as B in Bal data file.\n",
      "There are 288 entries classified as R in Bal data file.\n",
      "\n",
      "162 entries were classified in one cluster of which:\n",
      "\n",
      "Intersection of C1 with Balance L  149\n",
      "Intersection of C1 with Balance B  7\n",
      "Intersection of C1  with Balance R  6\n",
      "************************************* \n",
      "\n",
      "310 entries were classified in one cluster of which:\n",
      "\n",
      "intersection with Balance L  75\n",
      "intersection with Balance B  25\n",
      "intersection with Balance R  210\n",
      "************************************* \n",
      "153 entries were classified in one cluster of which:\n",
      "\n",
      "intersection with Balance L  64\n",
      "intersection with Balance B  17\n",
      "intersection with Balance R  72\n",
      "\n",
      "\n",
      "\n",
      "Adjusted rand Index:  0.0\n",
      "V measure score:  -1.70433894578e-15\n",
      "Calinski Harabaz Score:  122.127699482\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"****** Performance evaluation with Balance dataset *********\\n\\n\\n\" \n",
    "\n",
    "#f = StringIO(content)\n",
    "f=\"datasets/bal.arff\"\n",
    "data, meta = arff.loadarff(f)\n",
    "\n",
    "print len(data)\n",
    "a=[]\n",
    "\n",
    "data_num=np.zeros((len(data), len(data[0])-1))\n",
    "data_label=np.zeros((len(data)))\n",
    "\n",
    "i=0\n",
    "for d in data:\n",
    "    data_num[i,:]=[d[0],d[1],d[2],d[3]]\n",
    "    if d[4]==\"Iris-setosa\":\n",
    "        data_label[i]=0\n",
    "    if d[4]==\"Iris-versicolor\":\n",
    "        data_label[i]=1\n",
    "    if d[4]==\"Iris-virginica\":\n",
    "        data_label[i]=1\n",
    "                    \n",
    "    i=i+1    \n",
    "\n",
    "\n",
    "d_L=data_num[np.where(data[\"class\"]==\"L\")]\n",
    "d_B=data_num[np.where(data[\"class\"]==\"B\")]\n",
    "d_R=data_num[np.where(data[\"class\"]==\"R\")]\n",
    "\n",
    "\n",
    "cluster_assingment=Bk_means(data_num,3,2,0)\n",
    "\n",
    "results_c1=data_num[np.where(cluster_assingment[:]==0),:][0]\n",
    "results_c2=data_num[np.where(cluster_assingment[:]==1),:][0]\n",
    "results_c3=data_num[np.where(cluster_assingment[:]==2),:][0]\n",
    "\n",
    "\n",
    "print \"There are\", len(d_L) ,\"entries classified as L in Bal data file\"\n",
    "print \"There are\", len(d_B) ,\"entries classified as B in Bal data file.\"\n",
    "print \"There are\", len(d_R) ,\"entries classified as R in Bal data file.\\n\"\n",
    "\n",
    "print len(results_c1), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_L)).intersection(map(tuple, list(results_c1)))\n",
    "d=len(sett)\n",
    "print\"Intersection of C1 with Balance L \",d\n",
    "sett=set(map(tuple, d_B)).intersection(map(tuple, results_c1))\n",
    "d=len(sett)\n",
    "print \"Intersection of C1 with Balance B \",d\n",
    "sett=set(map(tuple, d_R)).intersection(map(tuple, results_c1))\n",
    "d=len(sett)\n",
    "print \"Intersection of C1  with Balance R \",d\n",
    "\n",
    "print \"************************************* \\n\"\n",
    "\n",
    "print len(results_c2), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_L)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance L \",d\n",
    "sett=set(map(tuple, d_B)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance B \",d\n",
    "sett=set(map(tuple, d_R)).intersection(map(tuple, results_c2))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance R \",d\n",
    "\n",
    "print \"************************************* \"\n",
    "\n",
    "print len(results_c3), \"entries were classified in one cluster of which:\\n\"\n",
    "sett=set(map(tuple, d_L)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance L \",d\n",
    "sett=set(map(tuple, d_B)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance B \",d\n",
    "sett=set(map(tuple, d_R)).intersection(map(tuple, results_c3))\n",
    "d=len(sett)\n",
    "print \"intersection with Balance R \",d\n",
    "\n",
    "print \"\\n\\n\"\n",
    "\n",
    "print \"Adjusted rand Index: \" , sk_cluster_m.adjusted_rand_score(data_label.flatten(), cluster_assingment)\n",
    "print \"V measure score: \" , sk_cluster_m.v_measure_score(data_label.flatten(), cluster_assingment)\n",
    "print \"Calinski Harabaz Score: \", skmetrics.calinski_harabaz_score(data_num, cluster_assingment) \n",
    "print \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
